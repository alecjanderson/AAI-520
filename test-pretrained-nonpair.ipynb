{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b4c0a0",
   "metadata": {
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1696283722724,
     "user": {
      "displayName": "Alec Anderson",
      "userId": "10628656018086214733"
     },
     "user_tz": 420
    },
    "id": "e5b4c0a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aanderson/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from contractions import contractions_dict \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e044b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Definition & set padding\n",
    "model_name = 'microsoft/dialogpt-small'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2GdIDHUhWmeX",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696283249751,
     "user": {
      "displayName": "Alec Anderson",
      "userId": "10628656018086214733"
     },
     "user_tz": 420
    },
    "id": "2GdIDHUhWmeX"
   },
   "outputs": [],
   "source": [
    "movie_lines_path = '/Users/aanderson/Downloads/corpus/movie_lines.txt'\n",
    "movie_conversations_path = '/Users/aanderson/Downloads/corpus/movie_conversations.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bac7002",
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1696283250014,
     "user": {
      "displayName": "Alec Anderson",
      "userId": "10628656018086214733"
     },
     "user_tz": 420
    },
    "id": "0bac7002"
   },
   "outputs": [],
   "source": [
    "lines = open(movie_lines_path, encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "convers = open(movie_conversations_path, encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5efb0e",
   "metadata": {},
   "source": [
    "**Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab8de4d",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696283250014,
     "user": {
      "displayName": "Alec Anderson",
      "userId": "10628656018086214733"
     },
     "user_tz": 420
    },
    "id": "9ab8de4d"
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, max_len=13):\n",
    "        self.max_len = max_len\n",
    "        self._compile_regex()\n",
    "\n",
    "    def _compile_regex(self):\n",
    "        # Contractions\n",
    "        self.compiled_patterns = {re.compile(pattern): repl for pattern, repl in contractions_dict.items()}\n",
    "        # Retain important punctuation\n",
    "        self.clean_punctuations = re.compile(r'[^a-zA-Z0-9?.!,Â¿]')\n",
    "\n",
    "    def clean_text(self, txt):\n",
    "        txt = txt.lower()\n",
    "        for pattern, repl in self.compiled_patterns.items():\n",
    "            txt = pattern.sub(repl, txt)\n",
    "        txt = self.clean_punctuations.sub(' ', txt)\n",
    "        return txt.strip()\n",
    "\n",
    "    def preprocess_data(self, convers, lines):\n",
    "        exchange = [conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\", \"\").split() for conver in convers]\n",
    "        diag = {line.split(' +++$+++ ')[0]: line.split(' +++$+++ ')[-1] for line in lines}\n",
    "        questions, answers = self._extract_questions_answers(exchange, diag)\n",
    "        return questions, answers\n",
    "\n",
    "    def _extract_questions_answers(self, exchange, diag):\n",
    "        questions, answers = [], []\n",
    "        for conver in exchange:\n",
    "            for i in range(len(conver) - 1):\n",
    "                questions.append(diag.get(conver[i], ''))\n",
    "                answers.append(diag.get(conver[i + 1], ''))\n",
    "        sorted_ques = [q for q in questions if len(q.split()) < self.max_len]\n",
    "        sorted_ans = [a for q, a in zip(questions, answers) if len(q.split()) < self.max_len]\n",
    "        return sorted_ques, sorted_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0e1d9a",
   "metadata": {
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1696283563711,
     "user": {
      "displayName": "Alec Anderson",
      "userId": "10628656018086214733"
     },
     "user_tz": 420
    },
    "id": "ff0e1d9a"
   },
   "outputs": [],
   "source": [
    "max_len = 13\n",
    "max_seq_len = 40\n",
    "\n",
    "preprocessor = TextPreprocessor(max_len=max_len)\n",
    "sorted_ques, sorted_ans = preprocessor.preprocess_data(convers, lines)\n",
    "clean_ques = [preprocessor.clean_text(q) for q in sorted_ques]\n",
    "clean_ans = [preprocessor.clean_text(a) for a in sorted_ans]\n",
    "\n",
    "# Trimming answers and lists\n",
    "clean_ans = [' '.join(ans.split()[:11]) for ans in clean_ans]\n",
    "clean_ans = clean_ans[:1000]\n",
    "clean_ques = clean_ques[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e1a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"You're asking me out.  That's so cute. What's your name again?\", 'Cameron.', 'Why?']\n",
      "['Not the hacking and gagging and spitting part.  Please.', \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\", 'Forget it.', \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.']\n"
     ]
    }
   ],
   "source": [
    "# Before cleaning\n",
    "print(sorted_ques[:5])\n",
    "print(sorted_ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7eb9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well, i thought we would start with pronunciation, if that is okay with you.', 'not the hacking and gagging and spitting part.  please.', 'you are asking me out.  that is so cute. what is your name again?', 'cameron.', 'why?']\n",
      "['not the hacking and gagging and spitting part. please.', 'okay... then how bout we try out some french cuisine. saturday?', 'forget it.', 'the thing is, cameron i m at the mercy of a', 'unsolved mystery. she used to be really popular when she started']\n"
     ]
    }
   ],
   "source": [
    "# After cleaning\n",
    "print(clean_ques[:5])\n",
    "print(clean_ans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66987e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and dataloader\n",
    "class DialogDataset(Dataset):\n",
    "    def __init__(self, clean_ques, clean_ans, tokenizer, max_length):\n",
    "        self.clean_ques = clean_ques\n",
    "        self.clean_ans = clean_ans\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean_ques)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        inputs, targets = zip(*batch)\n",
    "        inputs = pad_sequence(inputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        targets = pad_sequence(targets, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        return inputs, targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.clean_ques[idx]\n",
    "        answer = self.clean_ans[idx]\n",
    "\n",
    "        question_tokenized = self.tokenizer(question, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        answer_tokenized = self.tokenizer(answer, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        return question_tokenized['input_ids'].squeeze(), answer_tokenized['input_ids'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d226b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader, split into train and val\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# Split\n",
    "train_ques, val_ques, train_ans, val_ans = train_test_split(clean_ques, clean_ans, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = DialogDataset(train_ques, train_ans, tokenizer, max_seq_len)\n",
    "val_dataset = DialogDataset(val_ques, val_ans, tokenizer, max_seq_len)\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=DialogDataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=DialogDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5f02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aanderson/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "LR = 5e-5\n",
    "\n",
    "# Early stopping\n",
    "best_val_loss = float('inf')\n",
    "no_improve = 0\n",
    "patience = 3  # for example\n",
    "\n",
    "# Model\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3010a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 2.5974228978157043, Validation Loss: 1.9105373322963715\n",
      "Epoch 1, Training Loss: 1.8802273869514465, Validation Loss: 1.668590784072876\n",
      "Epoch 2, Training Loss: 1.7250807136297226, Validation Loss: 1.599843680858612\n",
      "Epoch 3, Training Loss: 1.6536614745855331, Validation Loss: 1.5745927095413208\n",
      "Epoch 4, Training Loss: 1.6098138317465782, Validation Loss: 1.5422749817371368\n",
      "Epoch 5, Training Loss: 1.5674100741744041, Validation Loss: 1.5329861044883728\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    #Training\n",
    "    for batch_num, (batch_inputs, batch_targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_inputs, batch_targets = batch_inputs.to('cpu'), batch_targets.to('cpu')\n",
    "        \n",
    "        outputs = model(batch_inputs)\n",
    "        loss = loss_fn(outputs.logits.view(-1, outputs.logits.size(-1)), batch_targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "        \n",
    "        if batch_num != 0 and batch_num % 30 == 0:  \n",
    "            print(f\"Epoch {epoch}, Batch {batch_num}, Loss: {loss.item()}\")\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)  # compute the average loss for the epoch\n",
    "    \n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in val_dataloader:\n",
    "            batch_inputs, batch_targets = batch_inputs.to('cpu'), batch_targets.to('cpu')\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = loss_fn(outputs.logits.view(-1, outputs.logits.size(-1)), batch_targets.view(-1))\n",
    "            total_val_loss += loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    if no_improve == patience:\n",
    "        print(\"Early stopping!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text):\n",
    "    model.eval()\n",
    "    \n",
    "    input_tensor = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=max_seq_len)['input_ids'].to('cpu')\n",
    "    output_ids = model.generate(input_tensor, max_length=20, num_beams=5, temperature=0.7)\n",
    "    \n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Test\n",
    "print(get_response(\"Hello\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
